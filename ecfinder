#!/bin/bash

# Get the absolute path of the script and its directory
script_path="$(readlink -f "$0")"
script_dir="$(dirname "$script_path")"

# Parse command line arguments
while getopts "i:p:t:" option; do
  case "${option}" in
  i) input_dir=${OPTARG} ;;  # Input directory
  p) prob_cutoff=${OPTARG} ;;  # Probability cutoff
  t) max_cores=${OPTARG} ;;  # Max cores for parallel processing
  \?)
    echo "Invalid option: -$OPTARG" >&2
    exit 1
    ;;
  :)
    echo "Option -$OPTARG requires an argument." >&2
    exit 1
    ;;
  esac
done

# Get a list of directories for processing
directories=$(find "$input_dir" -mindepth 1 -maxdepth 1 -type d | grep -Ev '/\.DS_Store$' | sort -n)

####################
cnv_name="1000000.CNV.bedGraph"
mat_name="matrix.mtx"
lm_path=$script_dir"/coef_model_brain.txt"
####################


# Check if all necessary arguments are provided
if [[ -z $script_dir || -z $lm_path || -z $cnv_name || -z $mat_name || -z $input_dir || -z $prob_cutoff ]]; then
  echo "Missing one or more arguments." >&2
  exit 1
fi

echo "ecFinder found $(echo "$directories" | wc -l | sed 's/^[[:space:]]*//') cell(s)"

# Export variables so they can be accessed by parallel
export script_dir
export cell_name
export lm_path
export cnv_name
export mat_name
export input_dir
export prob_cutoff

# Function to execute R script for each directory
execute_command() {
  cell_dir="$1"
  python $script_dir/0_processing_per_cell.py "$cell_dir" "$script_dir" "$lm_path" "$cnv_name" "$mat_name" "$input_dir"
}

# Export the function to be used by parallel
export -f execute_command

# Use GNU parallel to process each directory in parallel
echo "$directories" | parallel -j $max_cores execute_command

python $script_dir/1_integration.py "$cell_dir" "$script_dir" "$input_dir" "$prob_cutoff"

exit 0